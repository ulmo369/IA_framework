# -*- coding: utf-8 -*-
"""Model with framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VLsS8pnCwalKd6TnpRIwDFfKlRgllRQh
"""
# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
import os


# Obtener el directorio actual (carpeta en la que nos encontramos)
current_directory = os.getcwd()
print("Directorio actual:", current_directory)
# Concatenar la ruta del archivo de datos a la ruta del directorio actual
data_file_path = os.path.join(current_directory, "Raisin_Dataset.csv")
print("Ruta completa del archivo:", data_file_path)

# Carga y lectura del data set
#columns = ["sepal length","sepal width","petal length","petal width", "class"]
df = pd.read_csv('Raisin_Dataset.csv')
#df = pd.read_csv('iris.data',names = columns)
df.head()

df.info()

df["Class"].replace({
    "Kecimen": 0,
    "Besni": 1
    }, inplace=True)
df[["Class"]].head(5)

# Creación del modelo de regresión lineal
model = LogisticRegression(fit_intercept=True)

# Asignación de "x" y "y" para el modelo
x = df[["MajorAxisLength", "MinorAxisLength"]]
y = df['Class']

# Separación de los datos en train y en test
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)

#Entrenamos el modelo

model.fit(x_train, y_train)

model.coef_

model.intercept_

#Train

# T R A I N : Predicciones del modelo
y_pred_train = model.predict(x_train)

# Exactitud del modelo en el conjunto de entrenamiento
accuracy_train = accuracy_score(y_train, y_pred_train)
print("Accuracy en el conjunto de entrenamiento:", accuracy_train)

# R-squared en el conjunto de entrenamiento
r2_train = r2_score(y_train, y_pred_train)
print("R-squared en el conjunto de entrenamiento:", r2_train)

#Test

# Predicciones en el conjunto de prueba
y_pred_test = model.predict(x_test)

# Exactitud del modelo en el conjunto de prueba
accuracy_test = accuracy_score(y_test, y_pred_test)
print("Accuracy en el conjunto de prueba:", accuracy_test)

# R-squared en el conjunto de prueba
r2_test = r2_score(y_test, y_pred_test)
print("R-squared en el conjunto de prueba:", r2_test)

#Cross validation

# Calcula el puntaje de validación cruzada en el conjunto de entrenamiento
scores = cross_val_score(model, x_train, y_train, cv=10, scoring="r2")

# Calcula la media de los puntajes de validación cruzada
mean_cv_score = abs(scores.mean())

print("cross validation score:", mean_cv_score)

# Mean Square Error de los datos predichos contra los datos reales
mse = mean_squared_error(y_test, y_pred_test)
print("Mean Squared Error en el conjunto de prueba:", mse)

df1 = df[["MajorAxisLength", "MinorAxisLength"]]
df2 = df[["Class"]]
data = pd.concat([df1, df2], axis=1)
data

# Matriz de confusión y reporte de clasificación
plt.figure(figsize=(5,5))
corr_matrix = data[["MajorAxisLength", "MinorAxisLength", "Class"]].corr()
sns.heatmap(corr_matrix, annot=True, linewidths=0.3, fmt='0.3f')
plt.show()


#Datos de entrenamiento vs datos predichos
plt.scatter(range(len(y_test)), y_test, label='y_test', alpha=.4, c = 'blue' )
plt.scatter(range(len(y_test)), y_pred_test, label='y_pred_test', alpha=.3, c = 'yellow')
plt.ylabel("y value")
plt.xlabel("Position")
plt.legend()
plt.title("Test data vs predicted data")
plt.show()